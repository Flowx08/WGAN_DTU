{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPPysUMOZxgz"
   },
   "source": [
    "## Generative adversarial networks\n",
    "### Generating of MNIST digits with a GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWaSbs51Z5lN"
   },
   "source": [
    "Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cV8YxhB6Z5lN",
    "outputId": "496666fa-2eae-4a1c-aa9c-c4afe585abe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (4.64.0)\n",
      "Requirement already satisfied: importlib-resources in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from tqdm) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from importlib-resources->tqdm) (3.6.0)\n",
      "Requirement already satisfied: torchsummary in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (1.5.1)\n",
      "Requirement already satisfied: pytorch-fid in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (0.2.1)\n",
      "Requirement already satisfied: torch>=1.0.1 in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from pytorch-fid) (1.10.1)\n",
      "Requirement already satisfied: numpy in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from pytorch-fid) (1.19.5)\n",
      "Requirement already satisfied: torchvision>=0.2.2 in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from pytorch-fid) (0.11.2)\n",
      "Requirement already satisfied: scipy in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from pytorch-fid) (1.5.4)\n",
      "Requirement already satisfied: pillow in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from pytorch-fid) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from torch>=1.0.1->pytorch-fid) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /zhome/ec/c/165037/cvenv/lib/python3.6/site-packages (from torch>=1.0.1->pytorch-fid) (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm\n",
    "!pip3 install torchsummary\n",
    "!pip3 install pytorch-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "TlFFUmfoZxg1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.utils.parametrizations as parametrizations\n",
    "from torchsummary import summary\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import grad as torch_grad\n",
    "import torchvision.transforms as transforms\n",
    "from IPython import display\n",
    "import matplotlib.pylab as plt\n",
    "import ipywidgets\n",
    "from torchvision.utils import save_image\n",
    "import pytorch_fid.fid_score as fid\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import zipfile \n",
    "import gdown\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKTYJngTuOtG"
   },
   "source": [
    "Check that we're running on GPU, and initialize our device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLcplSTKZxg4",
    "outputId": "8c46ef8c-3cf4-417b-8f00-326038ae649a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on GPU.\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"The code will run on GPU for MacOS devices with Metal programming framework.\")\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "    device = torch.device('cpu')\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lV2YzpnSuUwt"
   },
   "source": [
    "Setup our MNIST dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "hSXlDTz0Zxg7"
   },
   "outputs": [],
   "source": [
    "batch_size = 64               # Batch size\n",
    "nz = 100                      # Size of the input noise vector\n",
    "ngf = 24                      # Scale number of conv filters in generator\n",
    "ndf = 24                      # Scale number of conv filters in discriminator\n",
    "nc = 3                        # Number of channels in the output image (RGB or black and white ecc)\n",
    "model_input_size = 32         # Used to determine which model to use, options: (28, 32)\n",
    "datasetName = \"CELEBA\"         # Either MNIST, FashionMNIST, CIFAR10, CELEBA\n",
    "useLSGAN = False              # If enabled uses least squared criterion instead of binary cross entropy (only if useWGAN=False)\n",
    "useWGAN = False                # If true make the GAN a WGAN\n",
    "weights_clip_value = 0.01     # When using WGAN clip weights of discriminator in range (-clip, +clip)\n",
    "useWeightClipping = False\n",
    "useGradientPenality = False\n",
    "useSpectralNormalization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "4VT-RsQ0Z5lQ",
    "outputId": "7b1b0772-114a-4500-c089-d563dab23af0"
   },
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "if datasetName == \"MNIST\":\n",
    "  trainset = datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
    "                           transforms.Resize(32),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,)),\n",
    "                       ]))\n",
    "  train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "  testset = datasets.MNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "                           transforms.Resize(32),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,)),\n",
    "                       ]))\n",
    "  test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "elif datasetName == \"FashionMNIST\":\n",
    "  trainset = datasets.FashionMNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
    "                           transforms.Resize(32),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,)),\n",
    "                       ]))\n",
    "  train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "  testset = datasets.FashionMNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "                           transforms.Resize(32),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,)),\n",
    "                       ]))\n",
    "  test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "elif datasetName == \"CIFAR10\":\n",
    "  trainset = datasets.CIFAR10('./data', train=True, download=True, transform=transforms.Compose([\n",
    "                           transforms.Resize(32),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                       ]))\n",
    "  train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "  testset = datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n",
    "                           transforms.Resize(32),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,)),\n",
    "                       ]))\n",
    "  test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "elif datasetName == 'CELEBA':\n",
    "    trainset = ImageFolder('./data/celeba/', transform=transforms.Compose([\n",
    "        transforms.Resize(32), transforms.CenterCrop(32), transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                       ]))\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat ‘./data/celeba/img_align_celeba’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!mv ./data/celeba/img_align_celeba ./data/celeba/faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7n3gtt6Z5lR"
   },
   "source": [
    "## DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhxprWbiZxg-"
   },
   "source": [
    "Implement **generator** network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "5N31KfHDYwjn"
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "aHYx5QejZxg_"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.reshapeModule = nn.Linear(nz, ngf * 8 * 4 * 4)\n",
    "\n",
    "        self.dcmodel = 0\n",
    "        if (model_input_size == 28):\n",
    "          self.dcmodel = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(    ngf,      nc, kernel_size=1, stride=1, padding=2, bias=False),\n",
    "            nn.Tanh()\n",
    "          )\n",
    "        elif (model_input_size == 32):\n",
    "          self.dcmodel = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( ngf * 8, ngf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.Conv2d( ngf * 2, nc, 3, 1, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "          )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # FEEDFOREWARD MODEL\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        #x = self.fullyconnected(x)\n",
    "        #x = x.view(x.size(0), 1, 28, 28)\n",
    "\n",
    "        # CONVOLUTIONAL MODEL\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.reshapeModule(x)\n",
    "        x = x.view(x.size(0), ngf * 8, 4, 4)\n",
    "        x = self.dcmodel(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGcxpGzQZxhD"
   },
   "source": [
    "Implement **discriminator** network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "e7GEvrDvZxhD"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        if (useSpectralNormalization == False):\n",
    "            self.outputDense = nn.Linear(ndf * 8 * 4 * 4, 1)\n",
    "        else:\n",
    "            self.outputDense = parametrizations.spectral_norm(nn.Linear(ndf * 8 * 4 * 4, 1))\n",
    "            \n",
    "        self.dcmodel = 0\n",
    "        if (model_input_size == 28):\n",
    "          self.dcmodel = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, 1, 3, 1, 0, bias=False),\n",
    "          )\n",
    "        elif (model_input_size == 32 and useSpectralNormalization == False):\n",
    "          self.dcmodel = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf * 2, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (nc) x 32 x 32\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.LayerNorm([ndf * 4, 16, 16]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 4, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.LayerNorm([ndf * 4, 8, 8]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            #nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "        )\n",
    "        elif (model_input_size == 32 and useSpectralNormalization == True):\n",
    "            self.dcmodel = nn.Sequential(\n",
    "            parametrizations.spectral_norm(nn.Conv2d(nc, ndf * 2, 3, 1, 1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (nc) x 32 x 32\n",
    "            parametrizations.spectral_norm(nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)),\n",
    "            nn.LayerNorm([ndf * 4, 16, 16]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            parametrizations.spectral_norm(nn.Conv2d(ndf * 4, ndf * 4, 4, 2, 1, bias=False)),\n",
    "            nn.LayerNorm([ndf * 4, 8, 8]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            parametrizations.spectral_norm(nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False)),\n",
    "            #nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # FEEDFOREWARD MODEL\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        #x = self.fulluconnected(x)\n",
    "\n",
    "        # CONVOLUTIONAL MODEL\n",
    "        x = self.dcmodel(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.outputDense(x)\n",
    "        if (not useWGAN and not useLSGAN):\n",
    "          x = torch.sigmoid(x)\n",
    "        x = x.view(x.size(0), 1)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "3ZEyJf434bY4"
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(d, real_data, generated_data):\n",
    "    if (str(device) == 'cuda'):\n",
    "        use_cuda = True\n",
    "    else:\n",
    "        use_cuda = False\n",
    "    gp_weight = 10\n",
    "    batch_size = real_data.size()[0]\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    if use_cuda:\n",
    "      alpha = alpha.cuda()\n",
    "    interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
    "    interpolated = Variable(interpolated, requires_grad=True)\n",
    "    if use_cuda:\n",
    "      interpolated = interpolated.cuda()\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    prob_interpolated = d(interpolated)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                               grad_outputs=torch.ones(prob_interpolated.size()).cuda() if use_cuda else torch.ones(\n",
    "                               prob_interpolated.size()),\n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "    # so flatten to easily take norm per example in batch\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "\n",
    "    # Derivatives of the gradient close to 0 can cause problems because of\n",
    "    # the square root, so manually calculate norm and add epsilon\n",
    "    gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "\n",
    "    # Return gradient penalty\n",
    "    return gp_weight * ((gradients_norm - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEwYmocXMjE6"
   },
   "source": [
    "FID function based on inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "2KF-Yqw-Z5lV"
   },
   "outputs": [],
   "source": [
    "def compute_fid(model, distribution_size=20):\n",
    "    model.eval()\n",
    "\n",
    "    # Create folders if not existing\n",
    "    if (not os.path.exists(\"dataset_real\")):\n",
    "        os.mkdir(\"./dataset_real\")\n",
    "    if (not os.path.exists(\"dataset_fake\")):\n",
    "        os.mkdir(\"./dataset_fake\")\n",
    "\n",
    "  # Empty the folders\n",
    "    files = glob.glob('dataset_real/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    files = glob.glob('dataset_fake/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "    # Get images from dataset\n",
    "    print(\"Generating images for FID calculation...\")\n",
    "    singleLoader = DataLoader(dataset=trainset, shuffle=True, batch_size=1)\n",
    "    for i in range(distribution_size):\n",
    "        # Save real\n",
    "        image, raget = next(iter(singleLoader))\n",
    "        x_changed = image[0].cpu().squeeze() / 2.0 + 0.5\n",
    "        save_image(x_changed, \"dataset_real/real_{}.png\".format(i))\n",
    "\n",
    "        # Save fake\n",
    "        target_image = model(make_noise(1, model.input_size)).detach()\n",
    "        target_image = target_image[0].cpu().squeeze() / 2 + 0.5\n",
    "        #target_image = torch.randn(3, 32, 32)\n",
    "        save_image(target_image, \"dataset_fake/fake_{}.png\".format(i))\n",
    "    print(\"Done\")\n",
    "    \n",
    "    # run FID script\n",
    "    num_avail_cpus = len(os.sched_getaffinity(0))\n",
    "    num_workers = min(num_avail_cpus, 8)\n",
    "    fidValue = fid.calculate_fid_given_paths([\"./dataset_real/\", \"./dataset_fake/\"], 50, device, 2048, num_workers)\n",
    "    \"\"\"\n",
    "    if (use_cuda):\n",
    "        params = ['python3', '-m', 'pytorch_fid', '--device', 'cuda:0', './dataset_fake/', './dataset_real/']\n",
    "    else:\n",
    "        params = ['python3', '-m', 'pytorch_fid', './dataset_fake/', './dataset_real/']\n",
    "    result = subprocess.run(params, stdout=subprocess.PIPE)\n",
    "    \n",
    "    # Get last line of output and extract float value\n",
    "    print(result.stdout)\n",
    "    fidValue = float(re.findall(\"\\d+\\.\\d+\", str(result.stdout.splitlines()[-1]))[0])\n",
    "    \"\"\"\n",
    "    \n",
    "    return fidValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWDuWiwP-pj6"
   },
   "source": [
    "Utility functions that are handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "iI6i8YWqZ5lT"
   },
   "outputs": [],
   "source": [
    "def make_ones(size):\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data.to(device)\n",
    "\n",
    "def make_filled(size, value):\n",
    "    data = Variable(torch.full(size, value))\n",
    "    return data.to(device)\n",
    "\n",
    "def make_zeros(size):\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data.to(device)\n",
    "\n",
    "#def make_noise(batch_size, size):\n",
    "#    return torch.randn(batch_size, size).to(device)\n",
    "\n",
    "def make_noise(batch_size, size):\n",
    "    return torch.randn(batch_size, size, 1, 1).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l14H49bUfLg8"
   },
   "source": [
    "Create generator and discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QsfeEOFfJsy",
    "outputId": "896c8cb4-8a21-4e02-b6af-9afc1a587fa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 48, 32, 32]           1,296\n",
      "         LeakyReLU-2           [-1, 48, 32, 32]               0\n",
      "            Conv2d-3           [-1, 96, 16, 16]          73,728\n",
      "         LayerNorm-4           [-1, 96, 16, 16]          49,152\n",
      "         LeakyReLU-5           [-1, 96, 16, 16]               0\n",
      "            Conv2d-6             [-1, 96, 8, 8]         147,456\n",
      "         LayerNorm-7             [-1, 96, 8, 8]          12,288\n",
      "         LeakyReLU-8             [-1, 96, 8, 8]               0\n",
      "            Conv2d-9            [-1, 192, 4, 4]         294,912\n",
      "        LeakyReLU-10            [-1, 192, 4, 4]               0\n",
      "           Linear-11                    [-1, 1]           3,073\n",
      "================================================================\n",
      "Total params: 581,905\n",
      "Trainable params: 581,905\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.50\n",
      "Params size (MB): 2.22\n",
      "Estimated Total Size (MB): 3.73\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 3072]         310,272\n",
      "   ConvTranspose2d-2            [-1, 192, 8, 8]         589,824\n",
      "       BatchNorm2d-3            [-1, 192, 8, 8]             384\n",
      "              ReLU-4            [-1, 192, 8, 8]               0\n",
      "   ConvTranspose2d-5           [-1, 96, 16, 16]         294,912\n",
      "       BatchNorm2d-6           [-1, 96, 16, 16]             192\n",
      "              ReLU-7           [-1, 96, 16, 16]               0\n",
      "   ConvTranspose2d-8           [-1, 48, 32, 32]          73,728\n",
      "       BatchNorm2d-9           [-1, 48, 32, 32]              96\n",
      "             ReLU-10           [-1, 48, 32, 32]               0\n",
      "           Conv2d-11            [-1, 3, 32, 32]           1,296\n",
      "             Tanh-12            [-1, 3, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 1,270,704\n",
      "Trainable params: 1,270,704\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.04\n",
      "Params size (MB): 4.85\n",
      "Estimated Total Size (MB): 6.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "d = Discriminator().to(device)\n",
    "d.apply(weights_init)\n",
    "summary(d, (nc, model_input_size, model_input_size))\n",
    "g = Generator(nz).to(device)\n",
    "g.apply(weights_init)\n",
    "summary(g, (nz, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrgB6QSxfRWK"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "fn8RKyxLZxhG",
    "outputId": "40fc9d4e-6379-4d55-c6f1-362b3c0207f0"
   },
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "if (useWGAN):\n",
    "  #d_opt = torch.optim.RMSprop(d.parameters(), lr=0.00005)\n",
    "  #g_opt = torch.optim.RMSprop(g.parameters(), lr=0.00005)\n",
    "  d_opt = torch.optim.Adam(d.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "  g_opt = torch.optim.Adam(g.parameters(),  lr=0.0001, betas=(0.5, 0.999))\n",
    "else:\n",
    "  d_opt = torch.optim.Adam(d.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "  g_opt = torch.optim.Adam(g.parameters(),  lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "# Choose loss function\n",
    "if (useLSGAN):\n",
    "  d_loss_fun = nn.MSELoss()\n",
    "else:\n",
    "  d_loss_fun = nn.BCELoss()\n",
    "\n",
    "# Setup training\n",
    "images_fig = plt.figure(figsize=(20,10))\n",
    "subplots = [plt.subplot(2, 6, k+1) for k in range(12)]\n",
    "num_epochs = 10\n",
    "if (useWGAN):\n",
    "  iterations_discriminator = 5\n",
    "else:\n",
    "  iterations_discriminator = 1\n",
    "\n",
    "# Set models to training mode\n",
    "d.train()\n",
    "g.train()\n",
    "epoch_size = len(train_loader)\n",
    "FIDValues = []\n",
    "timePassed = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # Reset\n",
    "    g_loss = d_loss = 0.0\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    subplots[-1].clear()\n",
    "\n",
    "    # Save models\n",
    "    torch.save(g.state_dict(), \"generator.pt\")\n",
    "    torch.save(d.state_dict(), \"discriminator.pt\")\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        \n",
    "        if ( ((epoch * epoch_size + i) % int(num_epochs * epoch_size / 10)) == 0):\n",
    "            FIDValues.append(compute_fid(g, 5000))\n",
    "\n",
    "            # Update FID plot\n",
    "            x = np.arange(0, len(FIDValues) * 5, step=5)\n",
    "            FID_fig, ax = plt.subplots(1)\n",
    "            ax.plot(x, FIDValues)\n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('FID')\n",
    "            ax.set_title('Training - FID score for each epoch')\n",
    "            FID_fig.savefig(\"training_fid.png\")\n",
    "            FID_fig.clear()\n",
    "\n",
    "        def train_discriminator(optimizer):\n",
    "            \n",
    "            #train discriminator to recognize real images\n",
    "            loss = 0.0\n",
    "            for k in range(iterations_discriminator):\n",
    "                d.zero_grad() #reset gradients\n",
    "\n",
    "                # Get batch of real images\n",
    "                x, target = next(iter(train_loader))\n",
    "                x_real = x.to(device)\n",
    "\n",
    "                # Get batch of fake images\n",
    "                x_fake = g(make_noise(batch_size, g.input_size))\n",
    "        \n",
    "                #remember to detach x_fake before using it to compute the discriminator loss\n",
    "                #otherwise the discriminator loss will backpropagate through the generator as well, which is unnecessary.\n",
    "                x_fake = x_fake.detach()\n",
    "\n",
    "                # Train discriminator on real images\n",
    "                prediction_real = d(x_real)\n",
    "                n_real = prediction_real.size(0) #get batch size\n",
    "\n",
    "                # Train discriminator on fake fake images\n",
    "                prediction_fake = d(x_fake)\n",
    "                n_fake = prediction_fake.size(0) #get batch size\n",
    "\n",
    "                # loss function\n",
    "                if (useWGAN):\n",
    "                  d_loss = -prediction_real.mean() + prediction_fake.mean()\n",
    "                else:\n",
    "                  d_loss = d_loss_fun(prediction_real, make_ones(n_real)) + d_loss_fun(prediction_fake, make_zeros(n_fake))\n",
    "\n",
    "                # gradient penality\n",
    "                if (useGradientPenality):\n",
    "                  gp = gradient_penalty(d, x_real, x_fake)\n",
    "                  d_loss += gp\n",
    "                \n",
    "                # Backprop\n",
    "                d_loss.backward()\n",
    "        \n",
    "                #update weights\n",
    "                optimizer.step()\n",
    "\n",
    "                # Clip discriminator weights\n",
    "                if (useWeightClipping):\n",
    "                  for parm in d.parameters():\n",
    "                    parm.data.clamp_(-weights_clip_value, weights_clip_value)\n",
    "                \n",
    "                # Update loss\n",
    "                loss += d_loss.detach().cpu().numpy()\n",
    "            return loss\n",
    "\n",
    "        def train_generator(optimizer):\n",
    "            g.zero_grad() #reset gradients\n",
    "\n",
    "            x_fake = g(make_noise(batch_size, g.input_size))\n",
    "        \n",
    "            #train generator to fool discriminator\n",
    "            prediction = d(x_fake)\n",
    "            n = prediction.size(0) #get batch size\n",
    "            if (useWGAN):\n",
    "              g_loss = -prediction.mean() # Maximize prediction\n",
    "            else:\n",
    "              g_loss = d_loss_fun(prediction, make_ones(n))\n",
    "            g_loss.backward()\n",
    "        \n",
    "            #update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            return g_loss.detach().cpu().numpy()\n",
    "        \n",
    "        #====================\n",
    "        # Update discriminator\n",
    "        #====================\n",
    "        #make real and fake image\n",
    "        d_losses.append(train_discriminator(d_opt))\n",
    "        d_loss += d_losses[-1]\n",
    "        \n",
    "        #========================\n",
    "        # Update generator\n",
    "        #========================\n",
    "        #feed random noise to generator\n",
    "        g_losses.append(train_generator(g_opt))\n",
    "        g_loss += g_losses[-1]\n",
    "        \n",
    "        assert(not np.isnan(d_loss))\n",
    "        #Plot results every 100 minibatches\n",
    "        if i % 100 == 0:\n",
    "            g.eval()\n",
    "            with torch.no_grad():\n",
    "                x_fake = g(make_noise(batch_size, g.input_size)).detach()\n",
    "                P = d(x_fake)\n",
    "                for k in range(11):\n",
    "                    x_fake_k = x_fake[k].cpu().squeeze() / 2 + 0.5 # between 0,1\n",
    "                    if (nc > 1): #change format with channels in the end for imshow\n",
    "                      x_fake_k = x_fake_k.swapaxes(0,1)\n",
    "                      x_fake_k = x_fake_k.swapaxes(1,2)\n",
    "                    if (nc == 1):\n",
    "                        subplots[k].imshow(x_fake_k, cmap='gray')\n",
    "                    else:\n",
    "                        subplots[k].imshow(x_fake_k)\n",
    "                    subplots[k].set_title('d(x)=%.2f' % P[k])\n",
    "                    subplots[k].axis('off')\n",
    "                #subplots[-1].cla()\n",
    "                subplots[-1].plot(np.arange(len(g_losses)), g_losses)\n",
    "                subplots[-1].plot(np.arange(len(d_losses)), d_losses)\n",
    "                #subplots[-1].set_xlabel('Probability of being real')\n",
    "                subplots[-1].set_title('Discriminator and generator training loss')\n",
    "                \n",
    "                title = 'Epoch {e} - minibatch {n}/{d} - FID_epoch: {l} - TimeLeft = {t}'.format(e=epoch+1,\n",
    "                    n=i, d=epoch_size, l=FIDValues[-1], t=(((num_epochs * epoch_size) / (epoch * epoch_size + i + 0.001)) * (time.time() - timePassed)) )\n",
    "                images_fig.suptitle(title, fontsize=20)\n",
    "                display.display(images_fig)\n",
    "                print('Epoch {}: g_loss: {:.8f} d_loss: {:.8f}\\r'.format(epoch, g_loss/max(1, i), d_loss/max(1, i)))\n",
    "                display.clear_output(wait=True)\n",
    "\n",
    "                # Set model to train\n",
    "                d.train()\n",
    "                g.train()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOn-eJq7MH8U"
   },
   "outputs": [],
   "source": [
    "#g.load_state_dict(torch.load(\"./models/generator_fashion_WGANGP.pt\"))\n",
    "#g.load_state_dict(torch.load(\"./models/generator_MNIST.pt\"))\n",
    "#print(FIDValues)\n",
    "#torch.save(g.state_dict(), \"generator.pt\")\n",
    "#torch.save(d.state_dict(), \"discriminator.pt\")\n",
    "#print(compute_fid(g, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('fid_values.csv', FIDValues, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, len(FIDValues[2:]), step=1) + 1\n",
    "FID_fig, ax = plt.subplots(1)\n",
    "ax.plot(x, FIDValues[2:])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('FID')\n",
    "ax.set_title('Training - FID score for each epoch')\n",
    "FID_fig.savefig(\"training_fid_celeba_WGANGP.png\")\n",
    "FID_fig.show()\n",
    "#FID_fig.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.eval()\n",
    "f, axs = plt.subplots(8, 8, figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "plt.subplots_adjust(hspace=0, wspace=0, left=0, bottom=0,)\n",
    "for ax in axs:\n",
    "    target_image = g(make_noise(1, g.input_size)).detach()\n",
    "    #target_image, target = next(iter(train_loader))\n",
    "    target_image = target_image[0].cpu().squeeze() / 2 + 0.5\n",
    "    target_image = target_image.swapaxes(0,1)\n",
    "    target_image = target_image.swapaxes(1,2)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.axis('off')\n",
    "    if (nc == 1):\n",
    "        ax.imshow(target_image, cmap='gray')\n",
    "    else:\n",
    "        ax.imshow(target_image)\n",
    "f.savefig(\"results.png\")\n",
    "#f.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeISJHuoU_fw"
   },
   "outputs": [],
   "source": [
    "!python3 -m pytorch_fid --device cuda:0 ./dataset_fake/ ./dataset_real/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
