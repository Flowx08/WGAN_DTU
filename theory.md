# 1. Generative Adversarial Networks
### Overview
Generative Adversarial Networks (GANs) are a type of deep learning algorithm used for generating new data samples that are similar to a training dataset. They consist of two main components: a generator network and a discriminator network. 
- The generator network takes in a fixed lenght random noise vector as input and generates new samples that are intended to be similar to the training dataset. 
- The discriminator network takes in samples from the training dataset and samples generated by the generator network and tries to distinguish between the two, so it returns a single value between 0 and 1 that is the probability that the image is real.
The generator and discriminator networks are trained simultaneously in a game-like manner, with the generator trying to produce samples that are realistic enough to fool the discriminator, and the discriminator trying to correctly identify the samples as real or generated. In this way, the two models are competing against each other, they are adversarial in the game theory sense, and are playing aÂ zero-sum game. Zero-sum means that when the discriminator successfully identifies real and fake samples, it is rewarded or no change is needed to the model parameters, whereas the generator is penalized with large updates to model parameters.
Over time, the generator becomes better at producing realistic samples, and the discriminator becomes better at identifying generated samples. The end result is a generator network that is able to produce new samples that are similar to the training dataset.

### Training instability
GANs are difficult to train for a number of reasons. 
- One reason is that the generator and discriminator networks are trained simultaneously in a game-like manner, with the generator trying to produce samples that are realistic enough to fool the discriminator, and the discriminator trying to correctly identify the samples as real or generated. This can lead to instability in the training process, as the performance of the generator and discriminator can have a complex, interdependent relationship.
- Another reason why GANs are difficult to train is that the objective function that is used to train the networks is not straightforward. The objective function for GANs is based on a minimax game, in which the generator tries to minimize the probability that the discriminator will correctly identify its samples, while the discriminator tries to maximize that probability. This can make it difficult to optimize the networks effectively, and can result in the training process converging to a suboptimal solution or even failing to converge at all.
- Additionally, GANs can be sensitive to the choice of hyperparameters, such as the learning rate and the number of training iterations. Choosing the right hyperparameters can be a challenging and time-consuming process, and can greatly affect the performance of the trained GAN.

### Mode Collapse
One potential problem that can arise during training is mode collapse, in which the generator produces only a limited number of samples and fails to capture the full diversity of the training dataset. This can limit the usefulness of the generated samples and make it difficult to train the GAN effectively.


# 2. Wesserstain GAN
### Overview
It is an extension of the GAN that seeks an alternate way of training the generator model to better approximate the distribution of data observed in a given training dataset.

Instead of using a discriminator to classify or predict the probability of generated images as being real or fake, the WGAN changes or replaces the discriminator model with a critic that **scores the realness or fakeness** of a given image.

This change is motivated by a mathematical argument that training the generator should seek a minimization of the distance between the distribution of the data observed in the training dataset and the distribution observed in generated examples. The argument contrasts different distribution distance measures, such as Kullback-Leibler (KL) divergence, Jensen-Shannon (JS) divergence, and the Earth-Mover (EM) distance, referred to as Wasserstein distance.

### Weight clipping
The original Wasserstein Generative Adversarial Network (WGAN) model uses weight clipping as a method for enforcing the k-Lipschitz constraint, which limits the maximum gradient of the discriminator's output with respect to the input samples. This constraint is important because it helps to ensure that the discriminator produces smooth, continuous output, which is necessary for the Earth Mover's distance (also known as the Wasserstein distance) to be a meaningful measure of the distance between the distributions of real and generated samples. This constraint limits the maximum gradient of the discriminator's output with respect to the input samples, which ensures that the output varies smoothly and continuously.

In the original WGAN model, the k-Lipschitz constraint is enforced by clipping the weights of the discriminator network to a fixed range. This has the effect of limiting the maximum gradient of the discriminator's output, and thus enforcing the k-Lipschitz constraint. While this method is effective, it can can lead to suboptimal solutions. Later versions of WGANs use other methods, such as gradient penalty, to enforce the k-Lipschitz constraint.

### Wesserstain loss
The loss function used in Wasserstein Generative Adversarial Networks (WGANs) is based on the Earth Mover's distance (also known as the Wasserstein distance). This distance is calculated as the difference between the expected values of the discriminator's output on real and generated samples. The goal of the generator is to minimize this distance, while the goal of the discriminator is to maximize it.

The loss function for the generator is defined as the negative of the expected value of the discriminator's output on the generated samples. This means that the generator tries to produce samples that will cause the discriminator to output low values, which will minimize the Earth Mover's distance and improve the performance of the WGAN.

The loss function for the discriminator is defined as the expected value of the discriminator's output on the real samples, minus the expected value of the discriminator's output on the generated samples. This means that the discriminator tries to output high values for real samples and low values for generated samples, which will maximize the Earth Mover's distance and improve the performance of the WGAN.

Overall, the loss function for WGANs is designed to optimize the Earth Mover's distance between the distributions of real and generated samples, with the generator trying to minimize the distance and the discriminator trying to maximize it.

### Changes compared to Vanilla GAN
Although the theoretical grounding for the WGAN is dense, the implementation of a WGAN requires a few minor changes to the standard deep convolutional GAN, or DCGAN.

Those changes are as follows:

- Use a linear activation function in the output layer of the critic model (instead of sigmoid).
- Use Wasserstein loss to train the critic and generator models that promote larger difference between scores for real and generated images.
- Constrain critic model weights to a limited range after each mini batch update (e.g. [-0.01,0.01]).
- Update the critic model more times than the generator each iteration (e.g. 5).
- Use the RMSProp version of gradient descent with small learning rate and no momentum (e.g. 0.00005).


# 3. Gradient Penalty
In Wasserstein Generative Adversarial Networks (WGANs), the gradient penalty is a regularization term that is added to the loss function to ensure that the discriminator network produces smooth, continuous output. This is important because WGANs use the Earth Mover's distance (also known as the Wasserstein distance) as their objective function, which is sensitive to sudden changes in the output of the discriminator.

The Earth Mover's distance is used as the objective function for training the networks. This distance is calculated as the difference between the expected values of the discriminator's output on real and generated samples. In other words, it measures the "distance" between the distributions of real and generated samples in the space defined by the discriminator's output.

However, this objective function is sensitive to sudden changes in the discriminator's output. For example, if the discriminator's output jumps from 0 to 1 at a certain point, this will have a large impact on the Earth Mover's distance and could cause problems during training. To avoid this, the gradient penalty is added to the loss function to encourage the discriminator to produce smooth, continuous output.

The gradient penalty is calculated by taking the gradient of the discriminator's output with respect to the input samples, and penalizing large gradients. This encourages the discriminator to produce output that varies smoothly and continuously, which helps to stabilize the training process and improve the performance of the WGAN.

The gradient penalty can be seen as a special case of the more general k-Lipschitz constraint, which imposes a limit on the maximum gradient of the discriminator's output with respect to the input samples. Essentially Gradient Penalty is a soft version of the Lipschitz constraint, which follows from the fact that functions are 1-Lipschitz if the gradients are of norm at most 1 everywhere. The squared difference from norm 1 is used as the gradient penalty.


# 4. Spectral Normalization
Spectral normalization is a technique used in Generative Adversarial Networks (GANs) and Wasserstein Generative Adversarial Networks (WGANs) to stabilize the training process and improve the performance of the generative model. It involves constraining the spectral norm of the weights of the discriminator network, which has the effect of limiting the maximum Lipschitz constant of the network and preventing the gradient of the loss function from becoming unstable.

The spectral norm of a matrix is a measure of the maximum amplification that can be achieved by multiplying the matrix with a vector. In the case of GANs and WGANs, the weights of the discriminator network can be seen as a matrix, and the input samples can be seen as vectors. By constraining the spectral norm of the weight matrix, we are effectively limiting the maximum amplification that can be applied to the input samples.

This has several benefits for the training process. 
- First, it ensures that the gradient of the loss function remains stable, which can help to prevent the training process from becoming unstable or diverging. 
- Second, it helps to prevent the discriminator network from becoming too powerful, which can lead to the generator being unable to learn effectively. 
- Finally, it can improve the quality of the generated samples by encouraging the discriminator to focus on important features of the training dataset.

Overall, spectral normalization is a useful technique for stabilizing the training process and improving the performance of GANs and WGANs. It is particularly useful when the objective function used in the model is sensitive to sudden changes in the output of the discriminator, such as in the case of the binary cross-entropy or the Earth Mover's distance.


# 5.  FrÃ©chet inception distance
FrÃ©chet inception distance (FID) is a metric for evaluating the performance of generative models, such as Generative Adversarial Networks (GANs). It measures the distance between the distributions of real and generated images in feature space, which is the space formed by the activations of a specific layer of a pre-trained inception network. The pre-trained inception network is used to extract features from the real and generated images, and the distance between the distributions of these features is calculated using the FrÃ©chet distance.

The FrÃ©chet distance is a measure of the similarity between two probability distributions. It is defined as the minimum distance that a sample from one distribution would need to travel in order to match the distribution of the other. In the case of FID, the two distributions being compared are the distributions of the real and generated images in feature space.

The FID score is calculated as the FrÃ©chet distance between the two distributions. A lower FID score indicates that the distributions are more similar and that the generated images are of higher quality. Therefore, FID is often used as a metric for evaluating the performance of generative models, with lower scores indicating better performance.